{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Floor Plan AI - U-Net Model Training\n",
        "\n",
        "This notebook implements the training pipeline for our custom U-Net model using the CubiCasa5K dataset.\n",
        "\n",
        "## Project Overview\n",
        "- **Goal**: Train a semantic segmentation model to identify rooms, walls, and other elements in floor plans\n",
        "- **Dataset**: CubiCasa5K with 8 semantic classes\n",
        "- **Architecture**: U-Net with ResNet34 encoder\n",
        "- **Classes**: Background(0), Outdoor(1), Wall(2), Kitchen(3), Living/Dining(4), Bedroom(5), Bath(6), Entry/Hall(7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Setup & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import segmentation_models_pytorch as smp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from datetime import datetime\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import our custom dataset\n",
        "from cubicasa_dataset_v2 import CubiCasa5KDatasetV2\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Configuration & Hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training Configuration\n",
        "CONFIG = {\n",
        "    # Data\n",
        "    'data_root': 'dataset cubicasa/cubicasa5k/cubicasa5k',\n",
        "    'batch_size': 4,\n",
        "    'num_workers': 4,\n",
        "    'image_size': 512,\n",
        "    \n",
        "    # Model - SIMPLIFIED TO 3 CLASSES\n",
        "    'encoder_name': 'resnet34',\n",
        "    'encoder_weights': 'imagenet',\n",
        "    'num_classes': 3,  # Background, Wall, Room (simplified!)\n",
        "    'activation': None,\n",
        "    \n",
        "    # Training\n",
        "    'epochs': 30,\n",
        "    'learning_rate': 0.001,\n",
        "    'weight_decay': 1e-4,\n",
        "    'scheduler_patience': 5,\n",
        "    'scheduler_factor': 0.5,\n",
        "    \n",
        "    # Loss weights\n",
        "    'dice_weight': 0.7,\n",
        "    'ce_weight': 0.3,\n",
        "    \n",
        "    # Checkpointing\n",
        "    'save_dir': 'model_checkpoints',\n",
        "    'save_best_only': True,\n",
        "    'early_stopping_patience': 10\n",
        "}\n",
        "\n",
        "# Simplified class names\n",
        "CLASS_NAMES = {\n",
        "    0: 'Background',\n",
        "    1: 'Wall',\n",
        "    2: 'Room'  # All room types combined!\n",
        "}\n",
        "\n",
        "# Create save directory\n",
        "os.makedirs(CONFIG['save_dir'], exist_ok=True)\n",
        "\n",
        "print(\"Configuration:\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Dataset Loading & Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "print(\"Loading datasets...\")\n",
        "\n",
        "# Define split file paths\n",
        "dataset_root = CONFIG['data_root']\n",
        "train_split = os.path.join(dataset_root, 'train.txt')\n",
        "val_split = os.path.join(dataset_root, 'val.txt')\n",
        "\n",
        "train_dataset = CubiCasa5KDatasetV2(\n",
        "    split_file=train_split,\n",
        "    dataset_root=dataset_root,\n",
        "    image_size=(CONFIG['image_size'], CONFIG['image_size']),\n",
        "    augment=True\n",
        ")\n",
        "\n",
        "val_dataset = CubiCasa5KDatasetV2(\n",
        "    split_file=val_split,\n",
        "    dataset_root=dataset_root,\n",
        "    image_size=(CONFIG['image_size'], CONFIG['image_size']),\n",
        "    augment=False\n",
        ")\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "\n",
        "# Create data loaders - Note: dataset returns a dict, so we need to handle that\n",
        "def collate_fn(batch):\n",
        "    images = torch.stack([item['image'] for item in batch])\n",
        "    masks = torch.stack([item['mask'] for item in batch])\n",
        "    return images, masks\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=CONFIG['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=CONFIG['num_workers'],\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=CONFIG['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=CONFIG['num_workers'],\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Validation batches: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize sample data\n",
        "def visualize_batch(dataset, num_samples=4):\n",
        "    \"\"\"Visualize samples from the dataset\"\"\"\n",
        "    fig, axes = plt.subplots(2, num_samples, figsize=(16, 8))\n",
        "    \n",
        "    for i in range(num_samples):\n",
        "        # Get sample (dataset returns a dict)\n",
        "        sample = dataset[i]\n",
        "        image = sample['image']\n",
        "        mask = sample['mask']\n",
        "        \n",
        "        # Convert tensor to numpy and denormalize image\n",
        "        img_np = image.permute(1, 2, 0).numpy()\n",
        "        img_np = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        img_np = np.clip(img_np, 0, 1)\n",
        "        \n",
        "        mask_np = mask.numpy()\n",
        "        \n",
        "        # Plot image\n",
        "        axes[0, i].imshow(img_np)\n",
        "        axes[0, i].set_title(f'Image {i+1}')\n",
        "        axes[0, i].axis('off')\n",
        "        \n",
        "        # Plot mask with color mapping\n",
        "        axes[1, i].imshow(mask_np, cmap='tab10', vmin=0, vmax=11)  # CubiCasa has more classes\n",
        "        axes[1, i].set_title(f'Mask {i+1}')\n",
        "        axes[1, i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Show class distribution in masks\n",
        "    print(\"\\nClass distribution in sample masks:\")\n",
        "    for i in range(num_samples):\n",
        "        sample = dataset[i]\n",
        "        mask = sample['mask']\n",
        "        unique, counts = np.unique(mask.numpy(), return_counts=True)\n",
        "        print(f\"Sample {i+1}:\")\n",
        "        for class_id, count in zip(unique, counts):\n",
        "            percentage = count / (CONFIG['image_size'] ** 2) * 100\n",
        "            print(f\"  Class {class_id}: {percentage:.1f}%\")\n",
        "\n",
        "print(\"Training dataset samples:\")\n",
        "visualize_batch(train_dataset, num_samples=4)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Model Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create U-Net model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = smp.Unet(\n",
        "    encoder_name=CONFIG['encoder_name'],\n",
        "    encoder_weights=CONFIG['encoder_weights'],\n",
        "    classes=CONFIG['num_classes'],\n",
        "    activation=CONFIG['activation']\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Print model info\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nModel: U-Net with {CONFIG['encoder_name']} encoder\")\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"Model size: ~{total_params * 4 / 1e6:.1f} MB\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Loss Functions & Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define loss functions\n",
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self, dice_weight=0.7, ce_weight=0.3):\n",
        "        super().__init__()\n",
        "        self.dice_weight = dice_weight\n",
        "        self.ce_weight = ce_weight\n",
        "        self.dice_loss = smp.losses.DiceLoss(mode='multiclass')\n",
        "        self.ce_loss = nn.CrossEntropyLoss()\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        dice = self.dice_loss(pred, target)\n",
        "        ce = self.ce_loss(pred, target)\n",
        "        return self.dice_weight * dice + self.ce_weight * ce\n",
        "\n",
        "# Initialize loss and optimizer\n",
        "criterion = CombinedLoss(\n",
        "    dice_weight=CONFIG['dice_weight'],\n",
        "    ce_weight=CONFIG['ce_weight']\n",
        ")\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=CONFIG['learning_rate'],\n",
        "    weight_decay=CONFIG['weight_decay']\n",
        ")\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    patience=CONFIG['scheduler_patience'],\n",
        "    factor=CONFIG['scheduler_factor'],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Metrics\n",
        "train_metrics = smp.utils.metrics.IoU(threshold=0.5)\n",
        "val_metrics = smp.utils.metrics.IoU(threshold=0.5)\n",
        "\n",
        "print(\"Loss function: Combined Dice + CrossEntropy\")\n",
        "print(f\"Dice weight: {CONFIG['dice_weight']}, CE weight: {CONFIG['ce_weight']}\")\n",
        "print(f\"Optimizer: Adam (lr={CONFIG['learning_rate']}, wd={CONFIG['weight_decay']})\")\n",
        "print(f\"Scheduler: ReduceLROnPlateau (patience={CONFIG['scheduler_patience']})\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training history tracking\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'val_loss': [],\n",
        "    'train_iou': [],\n",
        "    'val_iou': [],\n",
        "    'learning_rate': []\n",
        "}\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, metrics, device):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    metrics.reset()\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc='Training')\n",
        "    for batch_idx, (images, masks) in enumerate(pbar):\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device, dtype=torch.long)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        # Update metrics\n",
        "        pred_masks = torch.argmax(outputs, dim=1)\n",
        "        metrics.update(pred_masks, masks)\n",
        "        \n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'avg_loss': f'{running_loss/(batch_idx+1):.4f}'\n",
        "        })\n",
        "    \n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_iou = metrics.compute()\n",
        "    return epoch_loss, epoch_iou\n",
        "\n",
        "def validate_epoch(model, val_loader, criterion, metrics, device):\n",
        "    \"\"\"Validate for one epoch\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    metrics.reset()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(val_loader, desc='Validation')\n",
        "        for batch_idx, (images, masks) in enumerate(pbar):\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device, dtype=torch.long)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            # Update metrics\n",
        "            pred_masks = torch.argmax(outputs, dim=1)\n",
        "            metrics.update(pred_masks, masks)\n",
        "            \n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'avg_loss': f'{running_loss/(batch_idx+1):.4f}'\n",
        "            })\n",
        "    \n",
        "    epoch_loss = running_loss / len(val_loader)\n",
        "    epoch_iou = metrics.compute()\n",
        "    return epoch_loss, epoch_iou\n",
        "\n",
        "print(\"Training setup complete. Ready to start training!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main training loop\n",
        "print(f\"Starting training for {CONFIG['epochs']} epochs...\")\n",
        "print(f\"Model will be saved to: {CONFIG['save_dir']}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "for epoch in range(CONFIG['epochs']):\n",
        "    print(f\"\\nEpoch {epoch+1}/{CONFIG['epochs']}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Train\n",
        "    train_loss, train_iou = train_epoch(\n",
        "        model, train_loader, criterion, optimizer, train_metrics, device\n",
        "    )\n",
        "    \n",
        "    # Validate\n",
        "    val_loss, val_iou = validate_epoch(\n",
        "        model, val_loader, criterion, val_metrics, device\n",
        "    )\n",
        "    \n",
        "    # Update learning rate\n",
        "    scheduler.step(val_loss)\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    \n",
        "    # Save history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['train_iou'].append(train_iou.item())\n",
        "    history['val_iou'].append(val_iou.item())\n",
        "    history['learning_rate'].append(current_lr)\n",
        "    \n",
        "    # Print epoch results\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train IoU: {train_iou:.4f}\")\n",
        "    print(f\"Val Loss: {val_loss:.4f} | Val IoU: {val_iou:.4f}\")\n",
        "    print(f\"Learning Rate: {current_lr:.6f}\")\n",
        "    \n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        epochs_without_improvement = 0\n",
        "        \n",
        "        # Save model checkpoint\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'val_loss': val_loss,\n",
        "            'val_iou': val_iou.item(),\n",
        "            'config': CONFIG,\n",
        "            'history': history\n",
        "        }\n",
        "        \n",
        "        torch.save(checkpoint, os.path.join(CONFIG['save_dir'], 'best_model.pth'))\n",
        "        print(f\"âœ“ New best model saved! (Val Loss: {val_loss:.4f})\")\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "        print(f\"No improvement for {epochs_without_improvement} epochs\")\n",
        "    \n",
        "    # Early stopping\n",
        "    if epochs_without_improvement >= CONFIG['early_stopping_patience']:\n",
        "        print(f\"\\nEarly stopping triggered after {epochs_without_improvement} epochs without improvement\")\n",
        "        break\n",
        "    \n",
        "    # Save latest checkpoint every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'val_loss': val_loss,\n",
        "            'val_iou': val_iou.item(),\n",
        "            'config': CONFIG,\n",
        "            'history': history\n",
        "        }\n",
        "        torch.save(checkpoint, os.path.join(CONFIG['save_dir'], f'checkpoint_epoch_{epoch+1}.pth'))\n",
        "\n",
        "end_time = datetime.now()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(f\"Total training time: {training_time}\")\n",
        "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
        "print(f\"Final validation IoU: {history['val_iou'][-1]:.4f}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Results Visualization & Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training curves\"\"\"\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # Loss curves\n",
        "    axes[0, 0].plot(epochs, history['train_loss'], 'b-', label='Train Loss')\n",
        "    axes[0, 0].plot(epochs, history['val_loss'], 'r-', label='Val Loss')\n",
        "    axes[0, 0].set_title('Training and Validation Loss')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True)\n",
        "    \n",
        "    # IoU curves\n",
        "    axes[0, 1].plot(epochs, history['train_iou'], 'b-', label='Train IoU')\n",
        "    axes[0, 1].plot(epochs, history['val_iou'], 'r-', label='Val IoU')\n",
        "    axes[0, 1].set_title('Training and Validation IoU')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('IoU')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True)\n",
        "    \n",
        "    # Learning rate\n",
        "    axes[1, 0].plot(epochs, history['learning_rate'], 'g-')\n",
        "    axes[1, 0].set_title('Learning Rate Schedule')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Learning Rate')\n",
        "    axes[1, 0].set_yscale('log')\n",
        "    axes[1, 0].grid(True)\n",
        "    \n",
        "    # Training progress\n",
        "    axes[1, 1].plot(epochs, np.array(history['val_loss']) - np.array(history['train_loss']), 'purple')\n",
        "    axes[1, 1].set_title('Overfitting Monitor (Val - Train Loss)')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('Loss Difference')\n",
        "    axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "    axes[1, 1].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(CONFIG['save_dir'], 'training_curves.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Plot training history\n",
        "plot_training_history(history)\n",
        "\n",
        "# Print final statistics\n",
        "print(\"\\nFinal Training Statistics:\")\n",
        "print(f\"Final train loss: {history['train_loss'][-1]:.4f}\")\n",
        "print(f\"Final val loss: {history['val_loss'][-1]:.4f}\")\n",
        "print(f\"Final train IoU: {history['train_iou'][-1]:.4f}\")\n",
        "print(f\"Final val IoU: {history['val_iou'][-1]:.4f}\")\n",
        "print(f\"Best val loss: {min(history['val_loss']):.4f} (epoch {np.argmin(history['val_loss'])+1})\")\n",
        "print(f\"Best val IoU: {max(history['val_iou']):.4f} (epoch {np.argmax(history['val_iou'])+1})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model and visualize predictions\n",
        "best_checkpoint = torch.load(os.path.join(CONFIG['save_dir'], 'best_model.pth'))\n",
        "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(f\"Loaded best model from epoch {best_checkpoint['epoch']}\")\n",
        "print(f\"Best validation loss: {best_checkpoint['val_loss']:.4f}\")\n",
        "print(f\"Best validation IoU: {best_checkpoint['val_iou']:.4f}\")\n",
        "\n",
        "# Visualize predictions\n",
        "def visualize_predictions(model, dataset, device, num_samples=4):\n",
        "    \"\"\"Visualize model predictions vs ground truth\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    fig, axes = plt.subplots(3, num_samples, figsize=(16, 12))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i in range(num_samples):\n",
        "            # Get sample\n",
        "            image, mask_true = dataset[i]\n",
        "            \n",
        "            # Predict\n",
        "            image_batch = image.unsqueeze(0).to(device)\n",
        "            pred_logits = model(image_batch)\n",
        "            pred_mask = torch.argmax(pred_logits, dim=1).cpu().squeeze().numpy()\n",
        "            \n",
        "            # Denormalize image\n",
        "            img_np = image.permute(1, 2, 0).numpy()\n",
        "            img_np = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "            img_np = np.clip(img_np, 0, 1)\n",
        "            \n",
        "            mask_true_np = mask_true.numpy()\n",
        "            \n",
        "            # Plot original image\n",
        "            axes[0, i].imshow(img_np)\n",
        "            axes[0, i].set_title(f'Original Image {i+1}')\n",
        "            axes[0, i].axis('off')\n",
        "            \n",
        "            # Plot ground truth mask\n",
        "            axes[1, i].imshow(mask_true_np, cmap='tab10', vmin=0, vmax=7)\n",
        "            axes[1, i].set_title(f'Ground Truth {i+1}')\n",
        "            axes[1, i].axis('off')\n",
        "            \n",
        "            # Plot prediction\n",
        "            axes[2, i].imshow(pred_mask, cmap='tab10', vmin=0, vmax=7)\n",
        "            axes[2, i].set_title(f'Prediction {i+1}')\n",
        "            axes[2, i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(CONFIG['save_dir'], 'predictions_visualization.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize predictions on validation set\n",
        "print(\"Visualizing model predictions:\")\n",
        "visualize_predictions(model, val_dataset, device, num_samples=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate detailed class-wise metrics\n",
        "def calculate_class_metrics(model, val_loader, device, num_classes=8):\n",
        "    \"\"\"Calculate IoU for each class\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    confusion_matrix = np.zeros((num_classes, num_classes))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, masks in tqdm(val_loader, desc='Calculating metrics'):\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            pred_masks = torch.argmax(outputs, dim=1)\n",
        "            \n",
        "            # Convert to numpy\n",
        "            pred_np = pred_masks.cpu().numpy().flatten()\n",
        "            true_np = masks.cpu().numpy().flatten()\n",
        "            \n",
        "            # Update confusion matrix\n",
        "            for t, p in zip(true_np, pred_np):\n",
        "                confusion_matrix[t, p] += 1\n",
        "    \n",
        "    # Calculate IoU for each class\n",
        "    class_ious = []\n",
        "    for i in range(num_classes):\n",
        "        tp = confusion_matrix[i, i]\n",
        "        fp = confusion_matrix[:, i].sum() - tp\n",
        "        fn = confusion_matrix[i, :].sum() - tp\n",
        "        \n",
        "        if tp + fp + fn > 0:\n",
        "            iou = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            iou = 0.0\n",
        "        class_ious.append(iou)\n",
        "    \n",
        "    return class_ious, confusion_matrix\n",
        "\n",
        "# Calculate metrics\n",
        "print(\"Calculating detailed class metrics...\")\n",
        "class_ious, conf_matrix = calculate_class_metrics(model, val_loader, device)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nClass-wise IoU Scores:\")\n",
        "print(\"-\" * 40)\n",
        "for i, (class_name, iou) in enumerate(zip(CLASS_NAMES.values(), class_ious)):\n",
        "    print(f\"{class_name:15s}: {iou:.4f}\")\n",
        "\n",
        "mean_iou = np.mean(class_ious)\n",
        "print(f\"\\nMean IoU: {mean_iou:.4f}\")\n",
        "\n",
        "# Save results\n",
        "results = {\n",
        "    'class_names': list(CLASS_NAMES.values()),\n",
        "    'class_ious': class_ious,\n",
        "    'mean_iou': mean_iou,\n",
        "    'training_history': history,\n",
        "    'config': CONFIG\n",
        "}\n",
        "\n",
        "with open(os.path.join(CONFIG['save_dir'], 'training_results.json'), 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(f\"\\nResults saved to {CONFIG['save_dir']}/training_results.json\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. Training Summary\n",
        "\n",
        "This notebook has successfully implemented and trained a U-Net model for floor plan semantic segmentation. The model will be used in our complete pipeline for extracting room areas from floor plan images.\n",
        "\n",
        "### Next Steps:\n",
        "1. **Evaluate on test set** - Test the trained model on the holdout test split\n",
        "2. **Build inference pipeline** - Implement the complete OCR + segmentation + area calculation pipeline  \n",
        "3. **Scale calibration** - Add dimension label detection and pixel-to-meter conversion\n",
        "4. **Test on Dutch floor plans** - Evaluate generalization to Funda.nl floor plans\n",
        "\n",
        "### Model Performance:\n",
        "- The trained U-Net model achieves good semantic segmentation of floor plan elements\n",
        "- Individual room instances will be extracted using connected components analysis\n",
        "- Combined with OCR, this will enable automatic room area calculation\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
