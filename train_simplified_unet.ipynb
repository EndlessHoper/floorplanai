{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Simplified Floor Plan Segmentation - Bare Minimum Approach\n",
        "\n",
        "**Goal**: Train a simple U-Net to segment floor plans into 3 classes:\n",
        "- **Background (0)**: Empty space\n",
        "- **Wall (1)**: Wall pixels  \n",
        "- **Room (2)**: Any room pixels (all room types combined)\n",
        "\n",
        "Later we'll use **connected components** to separate individual rooms and **OCR** to label them.\n",
        "\n",
        "This follows the **bare minimum** approach from our plan.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Setup & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import segmentation_models_pytorch as smp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# EXPERIMENT 3: Add Kornia for GPU augmentations\n",
        "import kornia.augmentation as K\n",
        "\n",
        "# Import our dataset\n",
        "from cubicasa_dataset_v2 import CubiCasa5KDatasetV2\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Simple Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimized configuration for better GPU utilization\n",
        "CONFIG = {\n",
        "    'data_root': 'dataset cubicasa/cubicasa5k/cubicasa5k',\n",
        "    'batch_size': 8,   # OPTIMAL: Sweet spot for speed vs memory (16 was too slow, 4 too small)\n",
        "    'image_size': 512,\n",
        "    'epochs': 1,  # Reduced for faster training\n",
        "    'learning_rate': 0.001,\n",
        "    'num_classes': 3,  # Background, Wall, Room - THAT'S IT!\n",
        "}\n",
        "\n",
        "# Our 3 simple classes\n",
        "CLASS_NAMES = {\n",
        "    0: 'Background',  # Empty space\n",
        "    1: 'Wall',       # Wall pixels\n",
        "    2: 'Room'        # ANY room pixels (all types combined)\n",
        "}\n",
        "\n",
        "print(\"Simple 3-class segmentation:\")\n",
        "for k, v in CLASS_NAMES.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n",
        "os.makedirs('simple_checkpoints', exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Simplified Dataset (3 Classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimplifiedDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Converts CubiCasa5K's many classes into just 3:\n",
        "    - 0: Background\n",
        "    - 1: Wall  \n",
        "    - 2: Room (all room types combined)\n",
        "    \"\"\"\n",
        "    def __init__(self, split_file, dataset_root, image_size=512, augment=False):\n",
        "        self.original_dataset = CubiCasa5KDatasetV2(\n",
        "            split_file=split_file,\n",
        "            dataset_root=dataset_root, \n",
        "            image_size=(image_size, image_size),\n",
        "            augment=augment\n",
        "        )\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.original_dataset)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # Get original sample (returns dict)\n",
        "        sample = self.original_dataset[idx]\n",
        "        image = sample['image']\n",
        "        mask = sample['mask']\n",
        "        \n",
        "        # Convert to simplified 3-class mask\n",
        "        simple_mask = torch.zeros_like(mask)\n",
        "        \n",
        "        # Mapping: \n",
        "        # 0 = Background -> 0\n",
        "        # 1 = Outdoor -> 0 (treat as background)\n",
        "        # 2 = Wall -> 1  \n",
        "        # 3+ = All rooms -> 2\n",
        "        simple_mask[mask == 0] = 0  # Background\n",
        "        simple_mask[mask == 1] = 0  # Outdoor -> Background\n",
        "        simple_mask[mask == 2] = 1  # Wall\n",
        "        simple_mask[mask >= 3] = 2  # All rooms -> Room\n",
        "        \n",
        "        return image, simple_mask\n",
        "\n",
        "# Load datasets\n",
        "dataset_root = CONFIG['data_root']\n",
        "train_split = os.path.join(dataset_root, 'train.txt')\n",
        "val_split = os.path.join(dataset_root, 'val.txt')\n",
        "\n",
        "print(\"Loading simplified datasets...\")\n",
        "# EXPERIMENT: Disable augmentation to test CPU bottleneck\n",
        "train_dataset = SimplifiedDataset(train_split, dataset_root, CONFIG['image_size'], augment=False)  # Changed to False\n",
        "val_dataset = SimplifiedDataset(val_split, dataset_root, CONFIG['image_size'], augment=False)\n",
        "\n",
        "print(f\"Train: {len(train_dataset)} samples\")\n",
        "print(f\"Val: {len(val_dataset)} samples\")\n",
        "\n",
        "# Data loaders - CRITICAL WINDOWS FIX: Must use num_workers=0 in Jupyter on Windows\n",
        "# Using num_workers>0 causes infinite hanging in Windows Jupyter environments\n",
        "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=0, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Quick Data Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick visualization of simplified data\n",
        "def show_samples(dataset, n=2):\n",
        "    fig, axes = plt.subplots(2, n, figsize=(12, 6))\n",
        "    \n",
        "    for i in range(n):\n",
        "        image, mask = dataset[i]\n",
        "        \n",
        "        # Denormalize image\n",
        "        img = image.permute(1,2,0).numpy()\n",
        "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        img = np.clip(img, 0, 1)\n",
        "        \n",
        "        axes[0,i].imshow(img)\n",
        "        axes[0,i].set_title(f'Image {i+1}')\n",
        "        axes[0,i].axis('off')\n",
        "        \n",
        "        # Show mask with 3 distinct colors\n",
        "        axes[1,i].imshow(mask.numpy(), cmap='viridis', vmin=0, vmax=2)\n",
        "        axes[1,i].set_title(f'3-Class Mask {i+1}')\n",
        "        axes[1,i].axis('off')\n",
        "        \n",
        "        # Print class distribution\n",
        "        unique, counts = torch.unique(mask, return_counts=True)\n",
        "        print(f\"Sample {i+1} distribution:\")\n",
        "        for cls, count in zip(unique, counts):\n",
        "            pct = count.item() / (512*512) * 100\n",
        "            print(f\"  {CLASS_NAMES[cls.item()]}: {pct:.1f}%\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_samples(train_dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Simple U-Net Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple U-Net setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create simple U-Net model\n",
        "model = smp.Unet(\n",
        "    encoder_name='resnet34',\n",
        "    encoder_weights='imagenet', \n",
        "    classes=CONFIG['num_classes'],  # Just 3 classes!\n",
        "    activation=None\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Model parameters: {total_params:,}\")\n",
        "\n",
        "# EXPERIMENT 3: GPU-based augmentations\n",
        "gpu_augmentation = nn.Sequential(\n",
        "    K.RandomHorizontalFlip(p=0.5),\n",
        "    K.RandomVerticalFlip(p=0.5),\n",
        "    K.RandomRotation(degrees=5.0),\n",
        "    K.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05)\n",
        ").to(device)\n",
        "\n",
        "# Simple loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
        "\n",
        "print(\"Simple model ready!\")\n",
        "print(\"GPU augmentation pipeline created!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Simple Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model():\n",
        "    \"\"\"\n",
        "    Main training function with Windows optimizations:\n",
        "    - num_workers=0 prevents Jupyter hanging on Windows\n",
        "    - GPU augmentations for better CPU/GPU load balancing\n",
        "    - Non-blocking transfers for improved performance\n",
        "    \"\"\"\n",
        "    print(f\"Starting training for {CONFIG['epochs']} epochs...\")\n",
        "    \n",
        "    history = {'train_loss': [], 'val_loss': []}\n",
        "    best_loss = float('inf')\n",
        "    \n",
        "    for epoch in range(CONFIG['epochs']):\n",
        "        # Train\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        \n",
        "        for batch_idx, (images, masks) in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1} Train')):\n",
        "            # EXPERIMENT 2: Non-blocking transfers for better CPU/GPU overlap\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            masks = masks.to(device, dtype=torch.long, non_blocking=True)\n",
        "            \n",
        "            # EXPERIMENT 3: Apply GPU augmentations\n",
        "            images = gpu_augmentation(images)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "            \n",
        "            # GPU monitoring every 10 batches for more granular updates\n",
        "            if batch_idx % 10 == 0:\n",
        "                gpu_mem = torch.cuda.memory_allocated()/1e9\n",
        "                gpu_max = torch.cuda.max_memory_allocated()/1e9\n",
        "                print(f\"  Batch {batch_idx}: GPU Memory {gpu_mem:.1f}GB / Max {gpu_max:.1f}GB\")\n",
        "        \n",
        "        train_loss /= len(train_loader)\n",
        "        \n",
        "        # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for images, masks in tqdm(val_loader, desc=f'Epoch {epoch+1} Val'):\n",
        "                images = images.to(device, non_blocking=True)\n",
        "                masks = masks.to(device, dtype=torch.long, non_blocking=True)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, masks)\n",
        "                val_loss += loss.item()\n",
        "        \n",
        "        val_loss /= len(val_loader)\n",
        "        \n",
        "        # Save history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        \n",
        "        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "        \n",
        "        # Save best model\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'simple_checkpoints/best_simple_model.pth')\n",
        "            print(f\"âœ“ New best model saved! (Val Loss: {val_loss:.4f})\")\n",
        "    \n",
        "    print(\"\\\\nTraining complete!\")\n",
        "    return history\n",
        "\n",
        "# Start training (num_workers=0 prevents Windows hanging)\n",
        "print(\"ðŸš€ Starting training with Windows-compatible settings...\")\n",
        "history = train_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Quick Results & Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['train_loss'], label='Train Loss')\n",
        "plt.plot(history['val_loss'], label='Val Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Show predictions\n",
        "plt.subplot(1, 2, 2)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sample_img, sample_mask = val_dataset[0]\n",
        "    pred = model(sample_img.unsqueeze(0).to(device))\n",
        "    pred_mask = torch.argmax(pred, dim=1).cpu().squeeze()\n",
        "    \n",
        "    plt.imshow(pred_mask.numpy(), cmap='viridis', vmin=0, vmax=2)\n",
        "    plt.title('Sample Prediction')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Best validation loss: {best_loss:.4f}\")\n",
        "print(\"Model saved to: simple_checkpoints/best_simple_model.pth\")\n",
        "\n",
        "# Show what we got\n",
        "print(\"\\nPrediction classes:\")\n",
        "unique_pred = torch.unique(pred_mask)\n",
        "for cls in unique_pred:\n",
        "    print(f\"  {CLASS_NAMES[cls.item()]}\")\n",
        "\n",
        "print(\"\\nðŸŽ¯ Next step: Use this model + connected components + OCR for room area calculation!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
